{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from pathlib import Path\n",
    "import html\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import tumblr_crawler as tc\n",
    "from tumblr_crawler import Snapshot\n",
    "from fastai.vision.data import verify_images\n",
    "\n",
    "#Localpath = '/media/larkaa/storage/Pictures/tumblr'\n",
    "filename = '/media/larkaa/storage/Pictures/tumblr/blog_list.txt'\n",
    "\n",
    "with open(filename, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    sites = [list(line) for line in csv.reader(f)]\n",
    "sites = sites[1:]\n",
    "#print(sites[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['elmalo82', '', 'deleted'],\n",
       " ['thexplicitseu', '', ''],\n",
       " ['colorslashform', 'archived', ''],\n",
       " ['k-jeezy87', '', 'aka https://www.instagram.com/kjeezy87/?hl=fr'],\n",
       " ['chrisbassxx',\n",
       "  '',\n",
       "  \"'https://www.justusboys.com/forum/threads/424861-Chris-Bass'\"],\n",
       " ['sweatpantstrackiebulge', '', 'videos not so great'],\n",
       " ['weazelas', '', ' #pictures of men'],\n",
       " ['scottinno', '', ''],\n",
       " ['scottinnooriginals', '', 'artsy'],\n",
       " ['jock-boys', '', 'cartoon and boys'],\n",
       " ['hung-8inches', '', ''],\n",
       " ['justregulardudes', '', 'lots of fatties'],\n",
       " ['pennstatefrat', '', '#soft ends at 100'],\n",
       " ['alessandrouk', '', '# >5750'],\n",
       " ['publicfreaky', '', 'deleted lots of ethnic# ends at 350'],\n",
       " ['dudesjackingoff', '', ''],\n",
       " ['dickoutinpublic', '', 'good'],\n",
       " ['fleshjackit1', '', ''],\n",
       " ['bromoerotic', '', ''],\n",
       " ['buddybate', '', 'deleted'],\n",
       " ['jacknbro', '', 'deleted'],\n",
       " ['takeitoffoffoff', '', ''],\n",
       " ['beautifulmasculinity', '', 'artsy with labels'],\n",
       " ['studinthestreetsslutinthesheets', '', ''],\n",
       " ['batcyan', '', 'deleted'],\n",
       " ['thegreatgaycrusader', '', ''],\n",
       " ['ju68', '', ''],\n",
       " ['alessandrouk', '', ''],\n",
       " ['yaoi-everywhere', '', ''],\n",
       " ['guysthatiwantinme', '', ''],\n",
       " ['finlandtom', '', ''],\n",
       " ['mightymorphinpowerbottoms', '', ''],\n",
       " ['cock-in-public', 'archived', ''],\n",
       " ['bigjock', '', ''],\n",
       " ['porntendo', '', ''],\n",
       " ['c-u-e-c-4', '', ''],\n",
       " ['gaypublicslut', '', ''],\n",
       " ['bikeguy13', '', ''],\n",
       " ['Dorkslapped', '', '#real guys'],\n",
       " ['Cenlaman93', '', 'deleted'],\n",
       " ['jtestudboys', '', ''],\n",
       " ['chrisbassxx', 'archived', ''],\n",
       " ['cbxx12', 'archived', 'https://cascadr.co/blogs/cbxx12'],\n",
       " ['suckmynutz2', 'archived', 'deleted'],\n",
       " ['jeffyfuckingt', 'archived', ''],\n",
       " ['thegreatgaycrusader', 'archived', ''],\n",
       " ['zanoah90', 'archived', 'deleted'],\n",
       " ['powerbottomboys', 'archived', 'deleted'],\n",
       " ['lordoflemons', 'archived', ''],\n",
       " ['pickedapeck', 'archived', ''],\n",
       " ['vintagegaypics', 'archived', ''],\n",
       " ['Dorkslapped', 'archived', ''],\n",
       " ['absolutely-scandalous', 'archived', ''],\n",
       " ['banging-the-boy', '', ''],\n",
       " ['andrewmurdoch', '', ''],\n",
       " ['jock-boys', '', ''],\n",
       " ['themenstoiletnyc', '', ''],\n",
       " ['comeherre', '', ''],\n",
       " ['bros-butts-busting-nuts', '', ''],\n",
       " ['lsudude18', '', ''],\n",
       " ['instguys', '', ''],\n",
       " ['notsostraight', '', ''],\n",
       " ['exposedtease', '', ''],\n",
       " ['rxpial', '', 'young with some asians'],\n",
       " ['maxd96', '', ''],\n",
       " ['baitssss', '', ''],\n",
       " ['bludwingart', '', 'animations'],\n",
       " ['guysnakedbaits', '', ''],\n",
       " ['mangiacazzi', '', ''],\n",
       " ['masterofthehousedesign-com', '', 'artsy'],\n",
       " ['gwip', '', ''],\n",
       " ['yywhyy', '', ''],\n",
       " ['southernfratguy', '', ''],\n",
       " ['snapchathotguys', '', 'mostly real guys'],\n",
       " ['qualitydudes', '', ''],\n",
       " ['eclipsezero85', '', ''],\n",
       " ['super-hobbit-fan', '', ''],\n",
       " ['boarddog73', '', ''],\n",
       " ['roscoeperth', '', 'jocks'],\n",
       " ['atomshausofmen', '', ''],\n",
       " ['domleba', '', 'artsy'],\n",
       " ['cowboytejano', '', ''],\n",
       " ['t-u-m-b-l-r-s-u-c-k-s-me', '', ''],\n",
       " ['gentlemenallowed', '', ''],\n",
       " ['nottherifleman', '', ''],\n",
       " ['shamelessmen', '', ''],\n",
       " ['normyip', '', ''],\n",
       " ['tommytank4', '', ''],\n",
       " ['gayfotosgroup', '', 'http://gfgb.blogspot.com/?zx=ed75a00e9b51d5bb'],\n",
       " ['asmodayssexmagick', '', 'twitterlinks'],\n",
       " ['fhuokxdsbkm', '', ''],\n",
       " ['tomsluvs', '', ''],\n",
       " ['wayitssupposed2b', '', ''],\n",
       " ['jacksnewdick', '', ''],\n",
       " ['s-water1234', '', ''],\n",
       " ['alanh-me', '', ''],\n",
       " ['iwant2topu', '', ''],\n",
       " ['10boner', '', ''],\n",
       " ['batmanxxxrobin', '', ''],\n",
       " ['benzboiz', '', ''],\n",
       " ['buttbuds', '', ''],\n",
       " ['deepblowx', '', ''],\n",
       " ['holyholes', '', ''],\n",
       " ['menatworxs', '', ''],\n",
       " ['publiccoupls', '', ''],\n",
       " ['redheatfrat', '', ''],\n",
       " ['screamingin', '', ''],\n",
       " ['toy4boy', '', ''],\n",
       " ['sportynumbers', '', ''],\n",
       " ['dickmatize-me', '', ''],\n",
       " ['kinggda', '', ''],\n",
       " ['relivecolor', 'archived', ''],\n",
       " ['alphacum', '', ''],\n",
       " ['curvedcocks2', '', ''],\n",
       " ['amaral_82', 'not tumblr', 'elmalo82'],\n",
       " ['antique-erotic', '', 'twitter?'],\n",
       " ['menbulgesbuttssports', '', ''],\n",
       " ['sharing-with-strangers', '', ''],\n",
       " ['springtings', '', 'deleted one dude with twitter account'],\n",
       " ['athena143', '', 'guys doing sports'],\n",
       " ['bendiboi', '', 'Tom Bentley / Sawyer Kennith Edwards'],\n",
       " ['menwithagility', '', ''],\n",
       " ['thetombentley', '', 'Tom Bentley / Sawyer Kennith Edwards']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttor ip: 51.89.200.125\n",
      "1 of 2 cocksimusmaximus\n",
      "Directory does not exist\n",
      "800 https://cocksimusmaximus.tumblr.com/api/read?type=photo&num=50&start=800\n",
      "Ending at  800\n",
      "2 of 2 horny-hotguy\n",
      "Directory does not exist\n",
      "120200 https://horny-hotguy.tumblr.com/api/read?type=photo&num=50&start=120200\n",
      "Ending at  120200\n"
     ]
    }
   ],
   "source": [
    "stop=200000\n",
    "target = sites[73+13:]\n",
    "# http://robilwil.tumblr.com/\n",
    "#http://homemadecock.tumblr.com\n",
    "\n",
    "target = [['roommate-naked-videos','archived',0]]#,['chrisbassxx','archived',0]]\n",
    "target = [['homemadecock','',0]]\n",
    "target = [['simonstalenhag','',0]]\n",
    "target = [['warblanksexxx','',0]]\n",
    "target = [['cocksimusmaximus','',0], ['horny-hotguy','',0]]\n",
    "\n",
    "\n",
    "tot = len(target)\n",
    "cur = 1\n",
    "s = tc.get_tor_session()\n",
    "\n",
    "for site,_,_ in target:\n",
    "    print('{} of {}'.format(cur,tot),site)\n",
    "    \n",
    "    tag_count = tc.scrape(site,\n",
    "                       update=False,\n",
    "                       start=0,\n",
    "                       stop=stop,\n",
    "                       verbose=True,\n",
    "                       session=s)\n",
    "    time.sleep(1)\n",
    "        \n",
    "    #tag_count = tc.scrape(site,\n",
    "    #                   update=False,\n",
    "    #                   start=0,\n",
    "    #                   stop=stop,\n",
    "    #                   verbose=False)\n",
    "    #time.sleep(1)\n",
    "    cur+=1\n",
    "    #location = '/media/larkaa/storage/Pictures/tumblr/'+site\n",
    "    #verify_images(location,delete=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 of 2 cocksimusmaximus\n",
      "685 new images\n",
      "9 new images\n",
      "3 of 2 horny-hotguy\n",
      "1922 new images\n",
      "1568 new images\n"
     ]
    }
   ],
   "source": [
    "for site,_,_ in target:\n",
    "    print('{} of {}'.format(cur,tot),site)\n",
    "    \n",
    "    tag_count = tc.scrape(site,\n",
    "                       update=False,\n",
    "                       start=0,\n",
    "                       stop=stop,\n",
    "                       verbose=True,\n",
    "                       session=s)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.session()\n",
    "r = session.get(\"https://homemadecock.tumblr.com/api/read?type=photo&num=50&start=13000\", timeout=5).text\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r, features=\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_links(soup,'homemadecock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['https://farm3.staticflickr.com/2942/15328950065_719d0bf972_o.png', 'https://66.media.tumblr.com/51c5fec7ed9968d93b529bd43a01aa3e/tumblr_nd1870jmlu1s9g3m4o1_500.png']\n",
    "\n",
    "[x.split('_')[-1].split('.')[0] for x in a if _o.png]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(soup,site,update=False):\n",
    "    img_list = []\n",
    "    tag_list = []\n",
    "    caption_list = []\n",
    "    res = []    \n",
    "    temp = []\n",
    "    text = ''\n",
    "    d = dict()\n",
    "\n",
    "    for a in soup.find_all('post'):\n",
    "        photos = [x for x in re.findall(r'(https:[A-Za-z0-9./_]*?(?:\\.jpg|\\.png|\\.gif))', html.unescape(str(a))) \n",
    "        if 'avatar' not in x \n",
    "        and ('1280' in x or '540' in x or '500' in x) \n",
    "        and ' ' not in x]        \n",
    "        \n",
    "        if photos:\n",
    "                \n",
    "            unique = [x.split('_')[-2] for x in photos]\n",
    "            unique = list(set(unique))\n",
    "            #print('unique',unique)\n",
    "            #print(photos)\n",
    "            \n",
    "            for i in unique:\n",
    "                #find max res photo\n",
    "                print(i)\n",
    "                print(photos)\n",
    "                #print([int(x.split('_')[-1].split('.')[0]) for x in photos if (i in x and '75sq' not in x) and ('o.' not in x)])\n",
    "                try:\n",
    "                    max_res = max([int(x.split('_')[-1].split('.')[0]) for x in photos if i in x and '75sq' not in x ])\n",
    "                except:\n",
    "                    continue\n",
    "                photo = [x for x in photos if i in x if str(max_res) in x] [0]\n",
    "                \n",
    "                temp.append(photo)\n",
    "                \n",
    "                \n",
    "                # find photos with tags\n",
    "                for x in a.find_all('tag'):\n",
    "                    text = re.sub(\"<[^>]*>\", \"\",x.text)\n",
    "                    d[photo] = d.get(photo,'') + ';' + text.lower().rstrip('. ')\n",
    "            \n",
    "                # find photos with captions\n",
    "                for x in a.find_all('photo-caption'):\n",
    "                    \n",
    "                    text = re.sub(\"<[^>]*>\", \"\",x.text)\n",
    "                    d[photo] = d.get(photo,'') + ';' + text.lower().rstrip('. ')\n",
    "\n",
    "        #print(temp)\n",
    "        img_list.extend(list(set(temp)))\n",
    "        \n",
    "    #convert caption results to dictionary    \n",
    "    temp =[]\n",
    "    for key, value in d.items():\n",
    "        temp = [key,value]\n",
    "        res.append(temp)\n",
    "    \n",
    "\n",
    "    res = pd.DataFrame(res,columns = ['link','tags'])\n",
    "    tag_list = res\n",
    "    tag_list['tags'] = res.iloc[:,1].apply(lambda x: re.sub(r\"\\n\", \" \",re.sub('http\\S*','',x))[1:].rstrip('. '))\n",
    "    \n",
    "                \n",
    "    return(tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall('origin\":.\"(.+)\"',r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### removing bad videos\n",
    "vid = '/media/larkaa/storage/Pictures/tumblr/absolutely-scandalous/tumblr_onfopdIaHG1w0dwpv_480.mp4'\n",
    "#vid = 'HTML, CSS - Lecture 1 - CS50\\'s Web Programming with Python and JavaScript-XQs5KcUj-Do.webm'\n",
    "term = 'MacX'\n",
    "cmd = \"ffmpeg -i {} -f ffmetadata -hide_banner 2>&1 | grep {}\".format(vid,term)\n",
    "cmd = \"ffmpeg -i {} -f ffmetadata -hide_banner 2>&1\".format(vid)\n",
    "#cmd = \"grep -nr {} rockyou10_new.txt\".format(passwd)\n",
    "print(cmd)\n",
    "res= ! eval {cmd}\n",
    "\n",
    "\n",
    "print(any('MacX' in x for x in res))\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "folder = '/media/larkaa/storage/Pictures/tumblr/'\n",
    "onlyfiles = []\n",
    "for root, dirs, files in os.walk(folder): \n",
    "        #print(root)\n",
    "        for filename in files:\n",
    "            if filename.endswith(('.mp4','mkv','avi')):\n",
    "                onlyfiles.append(os.path.join(root,filename))\n",
    "                    \n",
    "#onlyfiles = [f for f in listdir(folder) if isfile(join(folder, f)) if f.endswith('mp4')]\n",
    "print(onlyfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://{0}.tumblr.com/api/read?type={1}&num={2}&start={3}\"\n",
    "\n",
    "test = base_url.format('cbxx12', 'photo', 50, 0)\n",
    "r = requests.get(test)\n",
    "print(test)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(r.text)\n",
    "# checking with xml....\n",
    "import html\n",
    "import xmltodict\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "rh = html.unescape(r.text)\n",
    "response = urllib.request.urlopen(media_url)\n",
    "soup = BeautifulSoup(response.read(), from_encoding=response.headers.get_content_charset())\n",
    "\n",
    "temp = soup.find_all('post')\n",
    "    \n",
    "xml_cleaned = print(re.sub(u'[^\\x20-\\x7f]+', u'', r.content.decode('utf-8')))\n",
    "\n",
    "data = xmltodict.parse(xml_cleaned)\n",
    "posts = data[\"tumblr\"][\"posts\"][\"post\"]\n",
    "for post in posts:\n",
    "    print(post)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#trying new site\n",
    "\n",
    "#http://www.queerclick.com/qc/2019/09/gwips-top-ten-of-the-week-110.php\n",
    "\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "site = 'http://guyswithiphones.com/'\n",
    "#r = requests.get(site)\n",
    "#r.text\n",
    "soup = BeautifulSoup(r.text)\n",
    "\n",
    "#<li><a href=\"http://guyswithiphones.com/2019/09/437804/\" \n",
    "#name=\"437804\" class=\"dlnk\">\n",
    "\n",
    "mydivs = soup.findAll(\"a\", {\"class\": \"dlnk\"})\n",
    "\n",
    "#for a in mydivs:\n",
    "#    print(a.get('href'))\n",
    "    \n",
    "\n",
    "# link to page, from then saved under 'realimg' / 'bigimg'\n",
    "#<div id=\"bigimg\">\n",
    "#<span class=\"realimage\"></span><img src=\"http://guyswithiphones.com/upload/user-2019/e84c9173-362f-491f-adee-f590d785be57.png\" width=\"1125\" height=\"2436\" \n",
    "#alt=\"Guys with iPhones\" />\n",
    "#</div>\n",
    "\n",
    "site2 = mydivs[0].get('href')\n",
    "print(site2)\n",
    "#r2 = requests.get(site2)\n",
    "soup2 = BeautifulSoup(r2.text)\n",
    "\n",
    "\n",
    "mydivs2 = soup2.findAll(\"img\", {\"alt\": \"Guys with iPhones\"})\n",
    "print(mydivs2[0].get('src'))\n",
    "\n",
    "#<div class=\"moreScroller\" style=\"width: 85px;\">\n",
    "#<a href=\"http://guyswithiphones.com/2019/09/437658/\"><img src=\"http://guyswithiphones.com/assets_c/2019/09/35459502_1845486752184383-thumb-76x76-302662.jpg\" width=\"75\"></a>\n",
    "#</div>\n",
    "\n",
    "mydivs3 = soup2.findAll(\"div\", {\"class\": \"moreScroller\"})\n",
    "for child in mydivs3:\n",
    "    print(child.find('a').get('href'))\n",
    "\n",
    "#for child in raw_quality:\n",
    "#    grade = child.find(class_ = 'grade').get_text()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#get all other pages\n",
    "#span class=\"yearboxes\">\n",
    "websites = [site]\n",
    "print()\n",
    "mydivs4 = soup.findAll(\"span\", {\"class\": \"yearboxes\"})\n",
    "for child in mydivs4:\n",
    "    #print(child)\n",
    "    temp = (child.findAll('a'))\n",
    "    for i in temp:\n",
    "        websites.append(i.get('href'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawl guyswithiphones\n",
    "import pandas as pd\n",
    "def crawl_gwip():\n",
    "    site = 'http://guyswithiphones.com/'\n",
    "    websites = [site]\n",
    "    soup = BeautifulSoup(requests.get(site).text)\n",
    "\n",
    "    ws = soup.findAll(\"span\", {\"class\": \"yearboxes\"})\n",
    "    for child in ws:\n",
    "        temp = (child.findAll('a'))\n",
    "        for i in temp:\n",
    "            websites.append(i.get('href'))\n",
    "    photos = []\n",
    "    for w in websites:\n",
    "        print(w,end=' ')\n",
    "        photos.extend(gwip_all_pages(w))\n",
    "    print(len(photos))\n",
    "    df = pd.DataFrame(photos)\n",
    "    df.to_csv('gwip_links.txt', index=False)\n",
    "\n",
    "#count = 1\n",
    "def gwip_all_pages(site):\n",
    "    global count\n",
    "    \n",
    "    photos = []\n",
    "    \n",
    "    #1 get website \n",
    "    r = requests.get(site)\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    \n",
    "    \n",
    "    # 2 get first level links\n",
    "    \n",
    "    links_1 = soup.findAll(\"a\", {\"class\": \"dlnk\"})\n",
    "    \n",
    "    #3 for each link, loop through to get photos\n",
    "    for l in links_1:\n",
    "        site2 = l.get('href')\n",
    "        #if count%1000==0:print(count,len(photos))\n",
    "        \n",
    "        while True:\n",
    "            r2 = requests.get(site2)\n",
    "            soup2 = BeautifulSoup(r2.text)\n",
    "            \n",
    "            mydivs2 = soup2.findAll(\"img\", {\"alt\": lambda L: L and \"Guys with iPhones\" in L})\n",
    "            photos.append(mydivs2[0].get('src'))\n",
    "            \n",
    "            # get other links if exist\n",
    "            mydivs3 = soup2.findAll(\"div\", {\"class\": \"moreScroller\"})\n",
    "            if mydivs3 and mydivs3[0].find('a'):\n",
    "                site2 = mydivs3[0].find('a').get('href')\n",
    "                #count+=1\n",
    "            else:\n",
    "                break\n",
    "            break\n",
    "                \n",
    "    print(len(photos))\n",
    "    return photos\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(photos)\n",
    "df.to_csv('gwip_links.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://guyswithiphones.com/upload/user-2020/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://guyswithiphones.com/2020/04/05/oxh59nc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://guyswithiphones.com/2020/04/05/oxyc6mS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://guyswithiphones.com/2020/04/05/oolbncF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://guyswithiphones.com/2020/04/05/ooohr0S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  https://guyswithiphones.com/upload/user-2020/i...\n",
       "1  https://guyswithiphones.com/2020/04/05/oxh59nc...\n",
       "2  https://guyswithiphones.com/2020/04/05/oxyc6mS...\n",
       "3  https://guyswithiphones.com/2020/04/05/oolbncF...\n",
       "4  https://guyswithiphones.com/2020/04/05/ooohr0S..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://guyswithiphones.com/ 48\n",
      "https://guyswithiphones.com/2020/01/31/ 16\n",
      "https://guyswithiphones.com/2020/02/29/ 15\n",
      "https://guyswithiphones.com/2020/03/31/ 16\n",
      "https://guyswithiphones.com/2020/04/05/ 9\n",
      "https://guyswithiphones.com/2019/01/31/ 16\n",
      "https://guyswithiphones.com/2019/02/28/ 16\n",
      "https://guyswithiphones.com/2019/03/31/ 17\n",
      "https://guyswithiphones.com/2019/04/30/ 16\n",
      "https://guyswithiphones.com/2019/05/31/ 16\n",
      "https://guyswithiphones.com/2019/06/30/ 16\n",
      "https://guyswithiphones.com/2019/07/31/ 16\n",
      "https://guyswithiphones.com/2019/08/31/ 18\n",
      "https://guyswithiphones.com/2019/09/30/ 17\n",
      "https://guyswithiphones.com/2019/10/31/ 18\n",
      "https://guyswithiphones.com/2019/11/30/ 17\n",
      "https://guyswithiphones.com/2019/12/31/ 16\n",
      "https://guyswithiphones.com/2018/01/31/ 51\n",
      "https://guyswithiphones.com/2018/02/28/ 42\n",
      "https://guyswithiphones.com/2018/03/31/ 58\n",
      "https://guyswithiphones.com/2018/04/30/ 60\n",
      "https://guyswithiphones.com/2018/05/31/ 61\n",
      "https://guyswithiphones.com/2018/06/30/ 22\n",
      "https://guyswithiphones.com/2018/07/31/ 18\n",
      "https://guyswithiphones.com/2018/08/31/ 16\n",
      "https://guyswithiphones.com/2018/09/30/ 16\n",
      "https://guyswithiphones.com/2018/10/31/ 25\n",
      "https://guyswithiphones.com/2018/11/30/ 18\n",
      "https://guyswithiphones.com/2018/12/31/ 20\n",
      "https://guyswithiphones.com/2017/01/31/ 58\n",
      "https://guyswithiphones.com/2017/02/28/ 54\n",
      "https://guyswithiphones.com/2017/03/31/ 53\n",
      "https://guyswithiphones.com/2017/04/30/ 56\n",
      "https://guyswithiphones.com/2017/05/31/ 52\n",
      "https://guyswithiphones.com/2017/06/30/ 34\n",
      "https://guyswithiphones.com/2017/07/31/ 55\n",
      "https://guyswithiphones.com/2017/08/31/ 58\n",
      "https://guyswithiphones.com/2017/09/30/ 39\n",
      "https://guyswithiphones.com/2017/10/31/ 61\n",
      "https://guyswithiphones.com/2017/11/30/ 54\n",
      "https://guyswithiphones.com/2017/12/31/ 54\n",
      "https://guyswithiphones.com/2016/01/31/ 68\n",
      "https://guyswithiphones.com/2016/02/29/ 41\n",
      "https://guyswithiphones.com/2016/03/31/ 61\n",
      "https://guyswithiphones.com/2016/04/30/ 62\n",
      "https://guyswithiphones.com/2016/05/31/ 63\n",
      "https://guyswithiphones.com/2016/06/30/ 72\n",
      "https://guyswithiphones.com/2016/07/31/ 62\n",
      "https://guyswithiphones.com/2016/08/31/ 56\n",
      "https://guyswithiphones.com/2016/09/30/ 35\n",
      "https://guyswithiphones.com/2016/10/31/ 61\n",
      "https://guyswithiphones.com/2016/11/30/ 49\n",
      "https://guyswithiphones.com/2016/12/31/ 30\n",
      "https://guyswithiphones.com/2015/01/31/ 67\n",
      "https://guyswithiphones.com/2015/02/28/ 61\n",
      "https://guyswithiphones.com/2015/03/31/ 75\n",
      "https://guyswithiphones.com/2015/04/30/ 71\n",
      "https://guyswithiphones.com/2015/05/31/ 69\n",
      "https://guyswithiphones.com/2015/06/30/ 66\n",
      "https://guyswithiphones.com/2015/07/31/ 56\n",
      "https://guyswithiphones.com/2015/08/31/ 75\n",
      "https://guyswithiphones.com/2015/09/30/ 74\n",
      "https://guyswithiphones.com/2015/10/31/ 82\n",
      "https://guyswithiphones.com/2015/11/30/ 75\n",
      "https://guyswithiphones.com/2015/12/31/ 71\n",
      "https://guyswithiphones.com/2014/01/31/ 34\n",
      "https://guyswithiphones.com/2014/02/28/ 54\n",
      "https://guyswithiphones.com/2014/03/31/ 57\n",
      "https://guyswithiphones.com/2014/04/30/ 51\n",
      "https://guyswithiphones.com/2014/05/31/ 56\n",
      "https://guyswithiphones.com/2014/06/30/ 65\n",
      "https://guyswithiphones.com/2014/07/31/ 53\n",
      "https://guyswithiphones.com/2014/08/31/ 1000 41\n",
      "60\n",
      "https://guyswithiphones.com/2014/09/30/ 49\n",
      "https://guyswithiphones.com/2014/10/31/ 78\n",
      "https://guyswithiphones.com/2014/11/30/ 66\n",
      "https://guyswithiphones.com/2014/12/31/ 48\n",
      "https://guyswithiphones.com/2013/01/31/ 51\n",
      "https://guyswithiphones.com/2013/02/28/ 53\n",
      "https://guyswithiphones.com/2013/03/31/ 58\n",
      "https://guyswithiphones.com/2013/04/30/ 44\n",
      "https://guyswithiphones.com/2013/05/31/ 60\n",
      "https://guyswithiphones.com/2013/06/30/ 60\n",
      "https://guyswithiphones.com/2013/07/31/ 57\n",
      "https://guyswithiphones.com/2013/08/31/ 53\n",
      "https://guyswithiphones.com/2013/09/30/ 62\n",
      "https://guyswithiphones.com/2013/10/31/ 95\n",
      "https://guyswithiphones.com/2013/11/30/ 51\n",
      "https://guyswithiphones.com/2013/12/31/ 51\n",
      "https://guyswithiphones.com/2012/01/31/ 70\n",
      "https://guyswithiphones.com/2012/02/29/ 72\n",
      "https://guyswithiphones.com/2012/03/31/ 91\n",
      "https://guyswithiphones.com/2012/04/30/ 87\n",
      "https://guyswithiphones.com/2012/05/31/ 96\n",
      "https://guyswithiphones.com/2012/06/30/ 94\n",
      "https://guyswithiphones.com/2012/07/31/ 95\n",
      "https://guyswithiphones.com/2012/08/31/ "
     ]
    },
    {
     "ename": "SSLError",
     "evalue": "HTTPSConnectionPool(host='guyswithiphones.com', port=443): Max retries exceeded with url: /2012/08/243474/ (Caused by SSLError(SSLError(\"bad handshake: SysCallError(110, 'ETIMEDOUT')\")))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSysCallError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m                 \u001b[0mcnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWantReadError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1933\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_do_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1934\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36m_raise_ssl_error\u001b[0;34m(self, ssl, result)\u001b[0m\n\u001b[1;32m   1662\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1663\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mSysCallError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrorcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1664\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSysCallError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Unexpected EOF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSysCallError\u001b[0m: (110, 'ETIMEDOUT')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0mssl_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mHAS_SNI\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mserver_hostname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad handshake: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSSLError\u001b[0m: (\"bad handshake: SysCallError(110, 'ETIMEDOUT')\",)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    719\u001b[0m             retries = retries.increment(\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='guyswithiphones.com', port=443): Max retries exceeded with url: /2012/08/243474/ (Caused by SSLError(SSLError(\"bad handshake: SysCallError(110, 'ETIMEDOUT')\")))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4db264bdc4f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwebsites\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mphotos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrawl_gwip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m#print(len(photos))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-24f17d41c1b6>\u001b[0m in \u001b[0;36mcrawl_gwip\u001b[0;34m(site)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0msoup2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m#print(site2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;31m# Resolve redirects if allowed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_redirects\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# Shuffle things around if there's history.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;31m# Resolve redirects if allowed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_redirects\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# Shuffle things around if there's history.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mresolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m                     \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                     \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                     \u001b[0;34m**\u001b[0m\u001b[0madapter_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m                 )\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_SSLError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# This branch is for urllib3 v1.22 and later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSSLError\u001b[0m: HTTPSConnectionPool(host='guyswithiphones.com', port=443): Max retries exceeded with url: /2012/08/243474/ (Caused by SSLError(SSLError(\"bad handshake: SysCallError(110, 'ETIMEDOUT')\")))"
     ]
    }
   ],
   "source": [
    "site = 'http://guyswithiphones.com/'\n",
    "websites = [site]\n",
    "soup = BeautifulSoup(requests.get(site).text)\n",
    "\n",
    "ws = soup.findAll(\"span\", {\"class\": \"yearboxes\"})\n",
    "for child in ws:\n",
    "    #print(child)\n",
    "    temp = (child.findAll('a'))\n",
    "    for i in temp:\n",
    "        websites.append(i.get('href'))\n",
    "\n",
    "photos = []\n",
    "#websites= ['http://guyswithiphones.com/2018/02/28/']\n",
    "for w in websites:\n",
    "    print(w,end=' ')\n",
    "    photos.extend(crawl_gwip(w))\n",
    "    #print(len(photos))\n",
    "\n",
    "print(len(photos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def dl_img_list(lst,path):\n",
    "    RETRY = 3\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "       'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "       'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "       'Accept-Encoding': 'none',\n",
    "       'Accept-Language': 'en-US,en;q=0.8',\n",
    "       'Connection': 'keep-alive'}\n",
    "\n",
    "    \n",
    "    \n",
    "    if not os.path.exists('{}'.format(path)):\n",
    "        os.makedirs(\"{}\".format(path))\n",
    "        print('Creating new directory')\n",
    "        \n",
    "    print(len(lst))\n",
    "    #count=1\n",
    "    for item in lst:\n",
    "        \n",
    "        dl_name = os.path.join(\"{}\".format(path),item.split('/')[-1]) \n",
    "        \n",
    "        my_file = Path(str(dl_name))\n",
    "        #if my_file.is_file(): print(my_file)\n",
    "        #print(my_file)\n",
    "        if not my_file.is_file():\n",
    "            retry_times = 0\n",
    "            while retry_times < RETRY:\n",
    "                try:\n",
    "                    with urllib.request.urlopen(item) as response, open(dl_name, 'wb') as out_file:\n",
    "                        data = response.read() # a `bytes` object\n",
    "                        out_file.write(data)\n",
    "\n",
    "                    break;\n",
    "                except:\n",
    "                    retry_times+=1 \n",
    "                    pass\n",
    "                retry_times+=1\n",
    "            #count+=1\n",
    "    #print(count)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pornhub serach and save videos\n",
    "def search_pornhub(search_term):\n",
    "    s_term = search_term.split(' ').join('+')\n",
    "    url = 'https://www.pornhub.com/gay/video/search?search='+s_term\n",
    "    r = requests.get(url)\n",
    "    res = re.findall('\"(/view_video\\.php.*?)\".*?title=\"(.*?)\"',r.text)\n",
    "    d={}\n",
    "    for value,key in res:\n",
    "        d[key] = d.get(key, value)\n",
    "        \n",
    "    count=1\n",
    "    for key, val in d.items():\n",
    "        i = 'https://www.pornhub.com'+val\n",
    "        cmd = 'youtube-dl {}'.format(i)\n",
    "        print(count, key)\n",
    "        res = ! eval {cmd}\n",
    "        count+=1\n",
    "    print('Downloaded {} videos'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usernames = [\"Awalpe75\", \"bodyheat75\", \"scruffy03\", \"thirty20\", \"elfton94\", \"venustus\", \"jmecparis\", \"windy\", \"dlishdd\", \"nelson7\", \"Matmat\", \"hung69olly\", \"Exotic_30\", \"arco\", \"bernexx\", \"kida26\", \"Tonio\", \"dudehayd\", \"botom59\", \"nickine\", \"~elektra~\", \"lebstud22\", \"Kunene\", \"Builtguy\", \"alala\", \"crbllm\", \"mikael83\", \"Arcon\", \"n2kinkdude\", \"mek_a_paris\", \"hotness84\", \"Gingernick\", \"ASB48\", \"gin+tonic\", \"grego75\", \"TheGoodBoy\", \"calirunner\", \"jock_model\", \"NYCVersGuy\", \"SwErik\", \"Frenchkik\", \"galfi14\", \"Rebel Yell\", \"pyramides\", \"paul660252\", \"Pronoia\", \"BeDe\", \"terrick\", \"big_blue\", \"Blitz-Ace\", \"madijames\", \"fldbgfun\", \"Bahquarius\", \"Dude1984\", \"rustola\", \"Ricardo29\", \"Exposure\", \"coolkid22\", \"blue_impul\", \"koni\", \"crazyman83\", \"Stargazer1\", \"Clivus\", \"fr_nudist\", \"candente1\", \"JNJ\", \"arc30\", \"Mi-Dou\", \"pussyboy4u\", \"bon_matos\", \"minac\", \"Sentry5\", \"officexxx\", \"Abnihilo\", \"uknik\", \"ACurtis802/Breakthru\", \"cuki\", \"Ollie09\", \"Reflet\", \"crewkid\", \"nickine\", ]\n",
    "res = []\n",
    "\n",
    "for i in usernames:\n",
    "    cmd = 'grep -nr {} /media/larkaa/storage/Torrents/BreachCompilation/data/'.format(i)\n",
    "    print(cmd)\n",
    "    temp= ! eval {cmd}\n",
    "    print(temp)\n",
    "    res.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vid_links(soup,site):\n",
    "    vid_list = []\n",
    "    d = dict()\n",
    "    a=''\n",
    "\n",
    "    #search all posts\n",
    "    for b in soup.find_all('post'):\n",
    "        #find vid links\n",
    "        temp = re.findall('source src=\\\"(https:.*?)\\\"'  , str(b))\n",
    "        if temp:\n",
    "            temp = temp[0]\n",
    "            if '480' not in temp:\n",
    "                #a_temp='https://vt.tumblr.com/'+(temp.split('/')[-1])\n",
    "                a_temp='https://ve.media.tumblr.com/'+(temp.split('/')[-1])\n",
    "            else:\n",
    "                #a_temp='https://vt.tumblr.com/'+(temp.split('/')[-2]+\"_480\")\n",
    "                a_temp='https://ve.media.tumblr.com/'+(temp.split('/')[-2]+\"_480\")\n",
    "            if a_temp.endswith('.mp4'):\n",
    "                a = a_temp\n",
    "            else:\n",
    "                a = a_temp + '.mp4'\n",
    "            \n",
    "            #add photo first, then include tags\n",
    "            d[a] = d.get(a,'')       \n",
    "            # find photos with tags\n",
    "            for x in b.find_all('tag'):\n",
    "                text = re.sub(\"<[^>]*>\", \"\",x.text)\n",
    "                d[a] = d.get(a,'') + ';' + text.lower().rstrip('. ')\n",
    "             \n",
    "            # find photos with captions\n",
    "            for x in b.find_all('photo-caption'):\n",
    "                text = re.sub(\"<[^>]*>\", \"\",x.text)\n",
    "                d[a] = d.get(a,'') + ';' + text.lower().rstrip('. ')\n",
    "                        \n",
    "    res =[]\n",
    "    for key, value in d.items():\n",
    "        temp = [key,value[1:]]\n",
    "        res.append(temp)\n",
    "\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/media/larkaa/storage/Pictures/tumblr/roommate-naked-videos/ve.media.tumblr.com_480.mp4'\n",
    "\n",
    "with open(file, 'rb') as f:\n",
    "    first = f.read(243)\n",
    "    \n",
    "print(first)\n",
    "print(re.findall('Denied',str(first)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
